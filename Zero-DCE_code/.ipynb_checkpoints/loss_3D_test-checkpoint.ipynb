{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4d4a15d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "图像尺寸torch.Size([1, 1, 32, 128, 128])，图像类型torch.float64\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'img_lowlight' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-663cb1b53457>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-663cb1b53457>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(config)\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[0mLoss_TV\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mL_TV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m     \u001b[0mloss_spa\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mL_spa\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menhanced_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_lowlight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[0mloss_col\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mL_color\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menhanced_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'img_lowlight' is not defined"
     ]
    }
   ],
   "source": [
    "# %load lowlight_train.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import time\n",
    "import dataloader\n",
    "import tifffile as tiff\n",
    "import model\n",
    "import Myloss_3D\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "\n",
    "def get_img(path):    #读取tiff格式和其它格式图片，主要为3维16位图片\n",
    "    if 'tif' in path:\n",
    "        img = tiff.imread(path)\n",
    "    else:\n",
    "        img = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
    "    \n",
    "    img = torch.tensor(img/65536)\n",
    "    img = img[np.newaxis, np.newaxis, :, :, :]\n",
    "    img = img[0:32, 0:32, 0:32]\n",
    "    \n",
    "#     img = img.permute(2, 0, 1)\n",
    "#     img = img.to(device)\n",
    "    \n",
    "    return img\n",
    "\n",
    "\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)\n",
    "\n",
    "\n",
    "def train(config):\n",
    "\n",
    "    os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "\n",
    "#     DCE_net = model.enhance_net_nopool().cuda()\n",
    "\n",
    "#     DCE_net.apply(weights_init)\n",
    "#     if config.load_pretrain == True:\n",
    "#         DCE_net.load_state_dict(torch.load(config.pretrain_dir))\n",
    "#     train_dataset = dataloader.lowlight_loader(config.lowlight_images_path)\n",
    "\n",
    "#     train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=config.train_batch_size, shuffle=True, num_workers=config.num_workers, pin_memory=True)\n",
    "\n",
    "\n",
    "    # 初始化loss函数\n",
    "    L_color = Myloss_3D.L_color()\n",
    "    L_spa = Myloss_3D.L_spa()\n",
    "\n",
    "    L_exp = Myloss_3D.L_exp(16,0.6)\n",
    "    L_TV = Myloss_3D.L_TV()\n",
    "    \n",
    "    # 读取图片，其中enhance image = enhanced image\n",
    "\n",
    "    img_path = 'data/883.tif'\n",
    "    img = get_img(img_path)\n",
    "    print('图像尺寸{}，图像类型{}'.format(img.shape, img.dtype))\n",
    "    \n",
    "    img_curve = np.random.rand(256)\n",
    "    \n",
    "    enhanced_image_1,enhanced_image,A  = img, img, None\n",
    "    \n",
    "    # loss部分\n",
    "    A = torch.load('A')\n",
    "    Loss_TV = 200*L_TV(A)\n",
    "\n",
    "    \n",
    "    print('L_spa的输入参数：enhance.shape:{}, lowlight.shape{}'.format(enhanced_image.shape, img_lowlight.shape))\n",
    "    loss_spa = torch.mean(L_spa(enhanced_image, img_lowlight))\n",
    "\n",
    "    loss_col = 5*torch.mean(L_color(enhanced_image))\n",
    "\n",
    "    loss_exp = 10*torch.mean(L_exp(enhanced_image))\n",
    "\n",
    "\n",
    "    # best_loss\n",
    "    loss =  Loss_TV + loss_spa + loss_col + loss_exp\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Input Parameters\n",
    "    parser.add_argument('--lowlight_images_path', type=str, default=\"data/train_data/\")\n",
    "    parser.add_argument('--lr', type=float, default=0.0001)\n",
    "    parser.add_argument('--weight_decay', type=float, default=0.0001)\n",
    "    parser.add_argument('--grad_clip_norm', type=float, default=0.1)\n",
    "    parser.add_argument('--num_epochs', type=int, default=200)\n",
    "    parser.add_argument('--train_batch_size', type=int, default=8)\n",
    "    parser.add_argument('--val_batch_size', type=int, default=4)\n",
    "    parser.add_argument('--num_workers', type=int, default=4)\n",
    "    parser.add_argument('--display_iter', type=int, default=10)\n",
    "    parser.add_argument('--snapshot_iter', type=int, default=10)\n",
    "    parser.add_argument('--snapshots_folder', type=str, default=\"snapshots/\")\n",
    "    parser.add_argument('--load_pretrain', type=bool, default= False)\n",
    "    parser.add_argument('--pretrain_dir', type=str, default= \"snapshots/Epoch99.pth\")\n",
    "    parser.add_argument(\"-f\", \"--fff\", help=\"a dummy argument to fool ipython\", default=\"1\")\n",
    "\n",
    "    config = parser.parse_args()\n",
    "\n",
    "    if not os.path.exists(config.snapshots_folder):\n",
    "        os.mkdir(config.snapshots_folder)\n",
    "\n",
    "\n",
    "    train(config)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
