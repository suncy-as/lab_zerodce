{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "614c5b9e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Total training examples: 3440\n",
      "---------------第0epochs-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda\\envs\\pytorch03\\lib\\site-packages\\torch\\nn\\functional.py:1374: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at iteration 10 : 0.3565103726195676   Loss_TV:0.0015269361363174968 + loss_spa:0.00024575279054736 + loss_exp:0.35473768369270275\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Invalid argument: 'snapshots/2023-11-03 20:47:06Epoch0.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-ed837e054de2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-19-ed837e054de2>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(config)\u001b[0m\n\u001b[0;32m     82\u001b[0m                 torch.save(DCE_net.state_dict(), config.snapshots_folder \n\u001b[0;32m     83\u001b[0m                            \u001b[1;33m+\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%Y-%m-%d %H:%M:%S'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m                            +\"Epoch\" + str(epoch) + '.pth')\n\u001b[0m\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data/loss/epochs_{}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda\\envs\\pytorch03\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol)\u001b[0m\n\u001b[0;32m    222\u001b[0m         \u001b[1;33m>>\u001b[0m\u001b[1;33m>\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \"\"\"\n\u001b[1;32m--> 224\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_with_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"wb\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda\\envs\\pytorch03\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_with_file_like\u001b[1;34m(f, mode, body)\u001b[0m\n\u001b[0;32m    145\u001b[0m             \u001b[1;33m(\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m3\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m         \u001b[0mnew_fd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    148\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 22] Invalid argument: 'snapshots/2023-11-03 20:47:06Epoch0.pth'"
     ]
    }
   ],
   "source": [
    "# %load lowlight_train.py\n",
    "# 对其进行改进，使其能训练2Dtif图像的模型\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import time\n",
    "import datetime\n",
    "import dataloader\n",
    "import model\n",
    "import Myloss\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)\n",
    "\n",
    "\n",
    "def train(config):\n",
    "\n",
    "    os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "\n",
    "    DCE_net = model.enhance_net_nopool().cuda()\n",
    "    \n",
    "    DCE_net.apply(weights_init)\n",
    "#     if config.load_pretrain == True:\n",
    "#         DCE_net.load_state_dict(torch.load(config.pretrain_dir))\n",
    "        \n",
    "    print(config.num_workers)\n",
    "    train_dataset = dataloader.lowlight_loader(config.lowlight_images_path)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=config.train_batch_size, \n",
    "                                               shuffle=True, num_workers=config.num_workers, \n",
    "                                               pin_memory=True)\n",
    "#     L_color = Myloss.L_color()\n",
    "    L_spa = Myloss.L_spa()\n",
    "    L_exp = Myloss.L_exp(16,0.6)\n",
    "    L_TV = Myloss.L_TV()\n",
    "    \n",
    "    optimizer = torch.optim.Adam(DCE_net.parameters(), lr=config.lr, weight_decay=config.weight_decay)\n",
    "\n",
    "    DCE_net.train()\n",
    "    \n",
    "    loss_list = []\n",
    "    for epoch in range(config.num_epochs):\n",
    "        print('---------------第{} epochs-------------'.format(epoch))\n",
    "        for iteration, img_lowlight in enumerate(train_loader):\n",
    "            img_lowlight = img_lowlight.cuda()\n",
    "\n",
    "            enhanced_image_1,enhanced_image,A  = DCE_net(img_lowlight)\n",
    "\n",
    "            Loss_TV = L_TV(A)\n",
    "            loss_spa = torch.mean(L_spa(enhanced_image, img_lowlight))\n",
    "#             loss_col = 5*torch.mean(L_color(enhanced_image))\n",
    "            loss_exp = torch.mean(L_exp(enhanced_image))\n",
    "\n",
    "            # best_loss\n",
    "            loss =  Loss_TV + loss_spa + loss_exp\n",
    "            loss_list.append([Loss_TV, loss_spa, loss_exp])\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "#             torch.nn.utils.clip_grad_norm(DCE_net.parameters(),config.grad_clip_norm)\n",
    "            optimizer.step()\n",
    "\n",
    "            if ((iteration+1) % config.display_iter) == 0:\n",
    "                print(\"Loss at iteration\", iteration+1, \":\", loss.item(),\n",
    "                      '  Loss_TV:{} + loss_spa:{} + loss_exp:{}'.format(Loss_TV , loss_spa , loss_exp))\n",
    "            if ((iteration+1) % config.snapshot_iter) == 0:\n",
    "                torch.save(DCE_net.state_dict(), config.snapshots_folder \n",
    "                           +datetime.datetime.now().strftime('%Y_%m_%d_%H_%M_%S_')\n",
    "                           +\"Epoch\" + str(epoch) + '.pth')\n",
    "            \n",
    "        np.save('data/loss/epochs_{}'.format(epoch+1), loss_list)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Input Parameters\n",
    "    parser.add_argument('--lowlight_images_path', type=str, default=\"E:/zero_dce_data/max_projection_img/\")\n",
    "    parser.add_argument('--lr', type=float, default=0.001)\n",
    "    parser.add_argument('--weight_decay', type=float, default=0.0001)\n",
    "    parser.add_argument('--grad_clip_norm', type=float, default=0.1)\n",
    "    parser.add_argument('--num_epochs', type=int, default=10)   # 200\n",
    "    parser.add_argument('--train_batch_size', type=int, default=64)    # 8\n",
    "    parser.add_argument('--val_batch_size', type=int, default=4)   # 4\n",
    "    parser.add_argument('--num_workers', type=int, default=1)         # 4\n",
    "    parser.add_argument('--display_iter', type=int, default=10)       # 10\n",
    "    parser.add_argument('--snapshot_iter', type=int, default=10)      # 10\n",
    "    parser.add_argument('--snapshots_folder', type=str, default=\"snapshots/\")\n",
    "    parser.add_argument('--load_pretrain', type=bool, default= False)    # False\n",
    "    parser.add_argument('--pretrain_dir', type=str, default= \"snapshots/Epoch99.pth\")\n",
    "    parser.add_argument('--h', type=str, default= \"snapshots/Epoch99.pth\")\n",
    "    parser.add_argument(\"-f\", \"--fff\", help=\"a dummy argument to fool ipython\", default=\"1\")\n",
    "\n",
    "    config = parser.parse_args()\n",
    "\n",
    "    if not os.path.exists(config.snapshots_folder):\n",
    "        os.mkdir(config.snapshots_folder)\n",
    "\n",
    "\n",
    "    train(config)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "215da5e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-03 20:46:11\n",
      "2023-11-03 20:46:11\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "print(datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "# 将当前时间转换为指定格式的字符串\n",
    "time_str = now.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# 输出时间字符串\n",
    "print(time_str)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
