{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad74d108",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\pytorch\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "D:\\anaconda\\envs\\pytorch\\lib\\site-packages\\torchvision\\io\\image.py:11: UserWarning: Failed to load image Python extension: [WinError 126] 找不到指定的模块。\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training examples: 1433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\86155\\AppData\\Roaming\\Python\\Python36\\site-packages\\ipykernel_launcher.py:74: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at iteration 10 : 0.3599997227262327 Loss_TV0.00014452328546255943 + loss_spa7.862492690879738e-09 + loss_exp0.35985519157827744\n",
      "Loss at iteration 20 : 0.3600454767350298 Loss_TV6.0754592283884015e-05 + loss_spa3.9884973546670875e-11 + loss_exp0.3599847221028609\n",
      "Loss at iteration 30 : 0.360018249799478 Loss_TV3.124671116860944e-05 + loss_spa1.3423898517359974e-10 + loss_exp0.3599870029540704\n",
      "Loss at iteration 40 : 0.3599378863103512 Loss_TV2.422330630562198e-05 + loss_spa3.097690355686184e-09 + loss_exp0.3599136599063552\n",
      "Loss at iteration 50 : 0.36000639128602935 Loss_TV1.42973735520102e-05 + loss_spa9.828009465926428e-11 + loss_exp0.3599920938141972\n",
      "Loss at iteration 60 : 0.35983823427480843 Loss_TV1.0399228209113683e-05 + loss_spa7.198851338277591e-08 + loss_exp0.35982776305808595\n",
      "Loss at iteration 70 : 0.35997833339151053 Loss_TV8.279820198167105e-06 + loss_spa2.8806326285170336e-09 + loss_exp0.3599700506906797\n",
      "Loss at iteration 80 : 0.35951820840616827 Loss_TV7.963829623893794e-06 + loss_spa1.755516208074217e-07 + loss_exp0.35951006902492355\n"
     ]
    }
   ],
   "source": [
    "# %load lowlight_train.py\n",
    "# 对其进行改进，使其能训练3D图像的模型\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import time\n",
    "# import dataloader\n",
    "# import model\n",
    "# import Myloss\n",
    "import dataloader_3D\n",
    "import model_3D\n",
    "import Myloss_3D\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)\n",
    "\n",
    "\n",
    "def train(config):\n",
    "\n",
    "    os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "\n",
    "    DCE_net = model_3D.enhance_net_nopool().cuda()\n",
    "    \n",
    "    DCE_net.apply(weights_init)\n",
    "#     if config.load_pretrain == True:\n",
    "#         DCE_net.load_state_dict(torch.load(config.pretrain_dir))\n",
    "        \n",
    "\n",
    "    train_dataset = dataloader_3D.lowlight_loader(config.lowlight_images_path)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=config.train_batch_size, \n",
    "                                               shuffle=True, num_workers=config.num_workers, \n",
    "                                               pin_memory=True)\n",
    "#     L_color = Myloss.L_color()\n",
    "    L_spa = Myloss_3D.L_spa()\n",
    "    L_exp = Myloss_3D.L_exp(16,0.6)\n",
    "    L_TV = Myloss_3D.L_TV()\n",
    "    \n",
    "    optimizer = torch.optim.Adam(DCE_net.parameters(), lr=config.lr, weight_decay=config.weight_decay)\n",
    "\n",
    "    DCE_net.train()\n",
    "\n",
    "    for epoch in range(config.num_epochs):\n",
    "        for iteration, img_lowlight in enumerate(train_loader):\n",
    "            img_lowlight = img_lowlight.cuda()\n",
    "\n",
    "            enhanced_image_1,enhanced_image,A  = DCE_net(img_lowlight)\n",
    "\n",
    "            Loss_TV = L_TV(A)\n",
    "            loss_spa = torch.mean(L_spa(enhanced_image, img_lowlight))\n",
    "#             loss_col = 5*torch.mean(L_color(enhanced_image))\n",
    "            loss_exp = torch.mean(L_exp(enhanced_image))\n",
    "\n",
    "            # best_loss\n",
    "            loss =  Loss_TV + loss_spa + loss_exp\n",
    "                        \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm(DCE_net.parameters(),config.grad_clip_norm)\n",
    "            optimizer.step()\n",
    "\n",
    "            if ((iteration+1) % config.display_iter) == 0:\n",
    "                print(\"Loss at iteration\", iteration+1, \":\", loss.item(),\n",
    "                      '  Loss_TV:{} + loss_spa:{} + loss_exp:{}'.format(Loss_TV , loss_spa , loss_exp))\n",
    "            if ((iteration+1) % config.snapshot_iter) == 0:\n",
    "                torch.save(DCE_net.state_dict(), config.snapshots_folder \n",
    "                           + \"Epoch\" + str(epoch) + '.pth')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Input Parameters\n",
    "    parser.add_argument('--lowlight_images_path', type=str, default=\"D:/zero_dce_data/img/\")\n",
    "    parser.add_argument('--lr', type=float, default=0.001)\n",
    "    parser.add_argument('--weight_decay', type=float, default=0.0001)\n",
    "    parser.add_argument('--grad_clip_norm', type=float, default=0.1)\n",
    "    parser.add_argument('--num_epochs', type=int, default=2)   # 200\n",
    "    parser.add_argument('--train_batch_size', type=int, default=1)    # 8\n",
    "    parser.add_argument('--val_batch_size', type=int, default=4)      # 4\n",
    "    parser.add_argument('--num_workers', type=int, default=0)         # 4\n",
    "    parser.add_argument('--display_iter', type=int, default=10)       # 10\n",
    "    parser.add_argument('--snapshot_iter', type=int, default=10)      # 10\n",
    "    parser.add_argument('--snapshots_folder', type=str, default=\"snapshots/\")\n",
    "    parser.add_argument('--load_pretrain', type=bool, default= False)    # False\n",
    "    parser.add_argument('--pretrain_dir', type=str, default= \"snapshots/Epoch99.pth\")\n",
    "    parser.add_argument('--h', type=str, default= \"snapshots/Epoch99.pth\")\n",
    "    parser.add_argument(\"-f\", \"--fff\", help=\"a dummy argument to fool ipython\", default=\"1\")\n",
    "\n",
    "    config = parser.parse_args()\n",
    "\n",
    "    if not os.path.exists(config.snapshots_folder):\n",
    "        os.mkdir(config.snapshots_folder)\n",
    "\n",
    "\n",
    "    train(config)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
